#!/usr/bin/env ansible-playbook
#
# (c) 2017 DataNexus Inc.  All Rights Reserved
---
# Build our kafka and zookeeper host groups
- name: Create kafka and zookeeper host groups
  hosts: localhost
  gather_facts: yes
  vars_files:
    - vars/kafka.yml
  tasks:
    # load the 'configuration file', if one was defined, to get any variables
    # we might need from that file when constructing our host groups
    - name: Load configuration file
      include_vars:
        file: "{{config_file | default('config.yml')}}"
    # if we're using dynamic provisioning; build the host groups from the
    # meta-data associated with the matching nodes in the selected cloud
    - block:
      # get a list of the node_map entries for this application
      - set_fact:
          node_map_entries: "{{node_map | selectattr('application', 'equalto', application) | list}}"
      # if more than one node_map entry was found or no matching node_map
      # entries were found, then it's an error
      - fail:
          msg: "Multiple {{application}} node_map entries found"
        when: node_map_entries | length > 1
      - fail:
          msg: "No {{application}} node_map entries found"
        when: node_map_entries | length == 0
      # build the kafka and zookeeper host groups from existing inventory
      - include_role:
          name: build-app-host-groups
        vars:
          host_group_list:
            - name: kafka
            - name: zookeeper
      - set_fact:
          num_kafka_nodes: "{{groups['kafka'] | default([]) | length}}"
          num_zk_nodes: "{{groups['zookeeper'] | default([]) | length}}"
      # if an existing set of Kafka nodes were found, throw an error unless
      # the reuse_existing_nodes flag was set to 'true' or 'yes')
      - block:
        - name: Fail playbook run if existing nodes found and user did not request reuse
          fail:
            msg: "Found an existing set of nodes - {{(groups['kafka'] | to_yaml).split('\n').0}}; aborting playbook run"
          when: not((reuse_existing_nodes | default(false)) | bool)
        when: num_kafka_nodes | int > 0
      # if an external Zookeeper ensemble (or node) was not found and we're
      # deploying an Kafka cluster (or multiple matching Kafka nodes were
      # found), then it's an error
      - fail:
          msg: "An external Zookeeper ensemble is required for Kafka cluster deployments"
        when:
          - (num_kafka_nodes | int == 0 and node_map_entries.0.count > 1) or num_kafka_nodes | int > 1
          - num_zk_nodes | int == 0
      # if there were no Kafka nodes found, then deploy a matching set of
      # instances into the target cloud environment, ensuring that there
      # are an appropriately tagged, based on the input tags and the node_map
      # entries for this application
      - include_role:
          name: 'aws'
        when: num_kafka_nodes | int == 0 and cloud == 'aws'
      - include_role:
          name: 'osp'
        when: num_kafka_nodes | int == 0 and cloud == 'osp'
      when: cloud is defined and (cloud == 'aws' or cloud == 'osp')

# If we're dynamically provisioning, then do some final configuration on the
# VMs that were just launched (assuming that we're not re-using existing VMs)
- name: Complete OS configuration
  hosts: kafka
  gather_facts: yes
  vars_files:
    - vars/kafka.yml
  tasks:
    # first, initialize the play
    - include_role:
        name: initialize-play
      vars:
        gather_facts: false
        skip_network_restart: true
    # if this is a cloud deployment and we need to (re)configure nodes...
    - block:
      # then run the `preflight` role to finish the configuration of the nodes
      # that were just allocated
      - include_role:
          name: preflight
        vars:
          mountpoint: "/data"
      # and set a fact indicating that we (re)configured nodes in this play
      - set_fact:
          configured_nodes: true
      when:
        - cloud is defined and (cloud == 'aws' or cloud == 'osp')
        - ((force_node_reconfig | default(false)) | bool) or ((hostvars['localhost']['num_kafka_nodes'] | int) == 0)

# Collect some Zookeeper related facts
- name: Gather facts from Zookeeper host group (if defined)
  hosts: zookeeper
  tasks: []

# And deploy Kafka to the nodes in the `kafka` host group; note that if
# there is more than one node in the `kafka` host group, those nodes will be
# configured as a Kafka cluster
- name: Install/configure Kafka server(s)
  hosts: kafka
  gather_facts: no
  vars_files:
    - vars/kafka.yml
  vars:
    - combined_package_list: "{{ (default_packages|default([])) | union(kafka_package_list) | union((install_packages_by_tag|default({})).kafka|default([])) }}"
    - kafka_nodes: "{{groups['kafka']}}"
    - zookeeper_nodes: "{{groups['zookeeper'] | default([])}}"
  pre_tasks:
    # first, initialize the play by loading any `local_vars_file` that may have
    # been passed in, restarting the network on the target nodes (if desired),
    # and determining the `data_iface` and `api_iface` values from the input
    # `iface_description_array` (if one was passed in)
    - include_role:
        name: initialize-play
      vars:
        skip_network_restart: "{{configured_nodes | default(false)}}"
    # and now that we know the name of our `data_iface`, we can construct the
    # list of zk_nodes (the data_iface IP addresses of our zookeeper_nodes)
    - set_fact:
        zk_nodes: "{{(zookeeper_nodes | default([])) | map('extract', hostvars, [('ansible_' + data_iface), 'ipv4', 'address']) | list}}"
  # now that we have all of the facts we need, provision the input nodes
  roles:
    - role: kafka
